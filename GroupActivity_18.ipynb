{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2507715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc2f81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv('../SupervisedML_13/diabetes.csv')\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d94df6",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04263995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking nulls in our dataset\n",
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f19a54",
   "metadata": {},
   "source": [
    "#### Why using .describe()?\n",
    "\n",
    "   * Are there any extreme values? (Outliers)\n",
    "   * Does any features has 0 values?\n",
    "   * Any features contains negative values?\n",
    "    \n",
    "* We would be able to answer those questions by using .describe() method for our entire dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd0bf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555adb9",
   "metadata": {},
   "source": [
    "* It seems like some features contains 0. There is a possibility for preganancy to be 0. But its not possible for other features(Glucose, BloodPressure, SkinThickness, Insulin, BMI). It might be, already our dataset has replaced Nans with 0s or kind of mistyping error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceb3710e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose : No. of 0s: 5\n",
      "BloodPressure : No. of 0s: 35\n",
      "SkinThickness : No. of 0s: 227\n",
      "Insulin : No. of 0s: 374\n",
      "BMI : No. of 0s: 11\n"
     ]
    }
   ],
   "source": [
    "# I am writing a function to check 0s in the columns. Keeping Columns which contains 0s in a list. \n",
    "zero_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "def check_zeros(df,features):\n",
    "    for i in features:\n",
    "        print('%s : No. of 0s: %d' %(i,len(df.loc[df[i]==0,i])))\n",
    "        \n",
    "# calling zero_features function\n",
    "check_zeros(diabetes_df,zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92dc803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose; Replaced 5 entries with value: 121.687\n",
      "BloodPressure; Replaced 35 entries with value: 72.405\n",
      "SkinThickness; Replaced 227 entries with value: 29.153\n",
      "Insulin; Replaced 374 entries with value: 155.548\n",
      "BMI; Replaced 11 entries with value: 32.457\n"
     ]
    }
   ],
   "source": [
    "# Skin Thickness and Insulin columns contains more 0s. Using function We can impute these 0s with their average values.\n",
    "# If we take mean for entire column, it will calculate including all 0s. So I am calculating only average of non zero\n",
    "# values.\n",
    "\n",
    "def impute_zeros(df, features):\n",
    "    nonzero_vals = df.loc[df[features] != 0, features]\n",
    "    avg = np.sum(nonzero_vals) / len(nonzero_vals)\n",
    "    k = len(df.loc[ df[features] == 0, features])   # num of 0-entries\n",
    "    df.loc[ df[features] == 0, features] = avg   # avg of non 0 values\n",
    "    print('%s; Replaced %d entries with value: %.3f' % (features, k, avg))\n",
    "    \n",
    "for i in zero_features:\n",
    "    impute_zeros(diabetes_df, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4206bd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.435949</td>\n",
       "      <td>12.096346</td>\n",
       "      <td>8.790942</td>\n",
       "      <td>85.021108</td>\n",
       "      <td>6.875151</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.750000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.202592</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  121.686763      72.405184      29.153420  155.548223   \n",
       "std       3.369578   30.435949      12.096346       8.790942   85.021108   \n",
       "min       0.000000   44.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.750000      64.000000      25.000000  121.500000   \n",
       "50%       3.000000  117.000000      72.202592      29.153420  155.548223   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  155.548223   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    32.457464                  0.471876   33.240885    0.348958  \n",
       "std      6.875151                  0.331329   11.760232    0.476951  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.500000                  0.243750   24.000000    0.000000  \n",
       "50%     32.400000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let me check again, whether we replaced all 0s are not\n",
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19aa80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other than pregnancies, all our zeros are replaced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cd9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = diabetes_df.iloc[:,:-1].values\n",
    "y = diabetes_df.iloc[:,-1].values\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=6, stratify=y)\n",
    "\n",
    "# Standardize\n",
    "sc= StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c547fa",
   "metadata": {},
   "source": [
    "### Using ANN with PyTorch Frame work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccde976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries from pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  # helps you to create and train neural networks\n",
    "import torch.nn.functional as F # F contains activation functions(sigmoid, relu, tanh, softmax, leaky relu etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89cb6069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1 and Loss 0.6573691368103027\n",
      "Epoch number 16 and Loss 0.46483901143074036\n",
      "Epoch number 31 and Loss 0.41151270270347595\n",
      "Epoch number 46 and Loss 0.3737669587135315\n",
      "Epoch number 61 and Loss 0.3302250802516937\n",
      "Epoch number 76 and Loss 0.2801561951637268\n",
      "Epoch number 91 and Loss 0.237721249461174\n",
      "Epoch number 106 and Loss 0.19606539607048035\n",
      "Epoch number 121 and Loss 0.1606629639863968\n",
      "Epoch number 136 and Loss 0.1325983852148056\n",
      "Epoch number 151 and Loss 0.10911095142364502\n",
      "Epoch number 166 and Loss 0.08828233927488327\n",
      "Epoch number 181 and Loss 0.07125198841094971\n",
      "Epoch number 196 and Loss 0.05782382935285568\n",
      "Epoch number 211 and Loss 0.047068022191524506\n",
      "Epoch number 226 and Loss 0.03843929246068001\n",
      "Epoch number 241 and Loss 0.03125106543302536\n",
      "Epoch number 256 and Loss 0.025269214063882828\n",
      "Epoch number 271 and Loss 0.02060263603925705\n",
      "Epoch number 286 and Loss 0.016625309363007545\n",
      "Epoch number 301 and Loss 0.013572918251156807\n",
      "Epoch number 316 and Loss 0.011256532743573189\n",
      "Epoch number 331 and Loss 0.009474093094468117\n",
      "Epoch number 346 and Loss 0.008106349967420101\n",
      "Epoch number 361 and Loss 0.007004437502473593\n",
      "Epoch number 376 and Loss 0.006091705057770014\n",
      "Epoch number 391 and Loss 0.00534217432141304\n",
      "Epoch number 406 and Loss 0.004737542476505041\n",
      "Epoch number 421 and Loss 0.004206007346510887\n",
      "Epoch number 436 and Loss 0.003778395475819707\n",
      "Epoch number 451 and Loss 0.003398398868739605\n",
      "Epoch number 466 and Loss 0.003079160349443555\n",
      "Epoch number 481 and Loss 0.002800124231725931\n",
      "Epoch number 496 and Loss 0.0025562765076756477\n"
     ]
    }
   ],
   "source": [
    "# creating tensors\n",
    "# All input features need to be converted as floating tensors\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train) \n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "\n",
    "# No need to convert to float tensors in case of output feature\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# artificial neural network class\n",
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self,input_nodes = 8, hidden1 = 20, hidden2 = 20, output_nodes = 2):\n",
    "        super().__init__()\n",
    "        self.hidden1_connection = nn.Linear(input_nodes, hidden1) # first hidden layer\n",
    "        self.hidden2_connection = nn.Linear(hidden1, hidden2) # second hidden layer\n",
    "        self.output_layer = nn.Linear(hidden2, output_nodes) # output layer\n",
    "    def forward(self,x):\n",
    "        # applying activation function to hidden layers\n",
    "        x = F.relu(self.hidden1_connection(x)) # F is torch.nn.functional\n",
    "        x = F.relu(self.hidden2_connection(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "# for results reproducibility setting random seed\n",
    "torch.manual_seed(6)\n",
    "\n",
    "# creating an object for class ANN_Model\n",
    "model = ANN_Model()\n",
    "\n",
    "# creating an object for loss function \n",
    "cross_loss = nn.CrossEntropyLoss() # diabetes dataset is binary classification problemm so we can use cross entropyloss\n",
    "\n",
    "# optimizer - is an algorithm that modifies attributes of nn such as weights and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # model.parameters() is a generator, so we can iterate and retirve all the parameter one by one\n",
    "\n",
    "# run model through multiple epochs(iterations)\n",
    "loss_list = []\n",
    "n_epochs = 500\n",
    "for i in range(n_epochs):\n",
    "    y_pred = model.forward(X_train_tensor) # predicting y using our ann model\n",
    "    loss = cross_loss(y_pred,y_train_tensor) # calculating the deviation between prediction and actual values\n",
    "    loss_list.append(loss) # appending losses in the list, forward propagation ends here\n",
    "    \n",
    "    # after every 10 epochs printing loss\n",
    "    if i % 15 == 1:\n",
    "        print('Epoch number {} and Loss {}' .format(i,loss))\n",
    "    \n",
    "    optimizer.zero_grad() # clear the gradient before running backward propagation\n",
    "    loss.backward() # backward propagation to find the derivative\n",
    "    optimizer.step()  # perform one optimization step each epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620c0e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       150\n",
      "           1       0.58      0.57      0.58        81\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.68      0.67      0.67       231\n",
      "weighted avg       0.70      0.71      0.70       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now that we have trained the network, we are going to use it in the testing set to make predictions.\n",
    "\n",
    "prediction = []\n",
    "with torch.no_grad(): # decreases memory consumption \n",
    "    for i, data in enumerate(X_test_tensor):\n",
    "        pred = model(data)\n",
    "        prediction.append(pred.argmax()) # returns index with max element in each prediction set\n",
    "from sklearn.metrics import classification_report,precision_score, recall_score\n",
    "print(classification_report(y_test_tensor,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9114ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have used Adam optimizer and checked my precision and recall. Now I am going to try other optimizers in Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c3d19",
   "metadata": {},
   "source": [
    "## 1. Look up the Adam optimization functions in PyTorch. How does it work? Try at least one other optimization function with the diabetes dataset shown in class. How does the model perform with the new optimizer? Did it perform better or worse than Adam? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703f110",
   "metadata": {},
   "source": [
    "### How does Adam optimization work?\n",
    "\n",
    "* The most important function of the optimizer is to update the weights of the learning algorithm to reach the least cost function. \n",
    "\n",
    "* ADAM (Adaptive Moment Estimation) algorithm works computing adaptive learning rates for each parameter at every iteration. It uses a combination of Gradient Descent with Momentum and RMSprop to determine the parameter values.\n",
    "\n",
    "* Adam has been used most widely in Deep Learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec7f30c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1 and Loss 0.24676987528800964\n",
      "Epoch number 16 and Loss 0.005101545248180628\n",
      "Epoch number 31 and Loss 0.004184851888567209\n",
      "Epoch number 46 and Loss 0.0037477882578969\n",
      "Epoch number 61 and Loss 0.0034690566826611757\n",
      "Epoch number 76 and Loss 0.0032693410757929087\n",
      "Epoch number 91 and Loss 0.003121255896985531\n",
      "Epoch number 106 and Loss 0.0030049977358430624\n",
      "Epoch number 121 and Loss 0.0029156634118407965\n",
      "Epoch number 136 and Loss 0.0028457792941480875\n",
      "Epoch number 151 and Loss 0.0027880542911589146\n",
      "Epoch number 166 and Loss 0.002737445756793022\n",
      "Epoch number 181 and Loss 0.0026917429640889168\n",
      "Epoch number 196 and Loss 0.002650950103998184\n",
      "Epoch number 211 and Loss 0.002614485565572977\n",
      "Epoch number 226 and Loss 0.0025809193029999733\n",
      "Epoch number 241 and Loss 0.002551501151174307\n",
      "Epoch number 256 and Loss 0.002523834817111492\n",
      "Epoch number 271 and Loss 0.0024979733861982822\n",
      "Epoch number 286 and Loss 0.0024755410850048065\n",
      "Epoch number 301 and Loss 0.0024549688678234816\n",
      "Epoch number 316 and Loss 0.0024364949204027653\n",
      "Epoch number 331 and Loss 0.0024188144598156214\n",
      "Epoch number 346 and Loss 0.0024018841795623302\n",
      "Epoch number 361 and Loss 0.0023858528584241867\n",
      "Epoch number 376 and Loss 0.002370459958910942\n",
      "Epoch number 391 and Loss 0.002356345998123288\n",
      "Epoch number 406 and Loss 0.002342653227970004\n",
      "Epoch number 421 and Loss 0.0023294179700315\n",
      "Epoch number 436 and Loss 0.0023175885435193777\n",
      "Epoch number 451 and Loss 0.002305730478838086\n",
      "Epoch number 466 and Loss 0.0022939539048820734\n",
      "Epoch number 481 and Loss 0.0022832814138382673\n",
      "Epoch number 496 and Loss 0.0022727875038981438\n",
      "Precision Score 0.61 for <class 'torch.optim.adagrad.Adagrad'>\n",
      "Recall Score 0.59 for <class 'torch.optim.adagrad.Adagrad'>\n",
      "Epoch number 1 and Loss 0.036261722445487976\n",
      "Epoch number 16 and Loss 0.008209820836782455\n",
      "Epoch number 31 and Loss 0.004308668896555901\n",
      "Epoch number 46 and Loss 0.0029422545339912176\n",
      "Epoch number 61 and Loss 0.002347672823816538\n",
      "Epoch number 76 and Loss 0.0020565432496368885\n",
      "Epoch number 91 and Loss 0.0018928435165435076\n",
      "Epoch number 106 and Loss 0.0017751359846442938\n",
      "Epoch number 121 and Loss 0.001671821577474475\n",
      "Epoch number 136 and Loss 0.0015848842449486256\n",
      "Epoch number 151 and Loss 0.0015064588515087962\n",
      "Epoch number 166 and Loss 0.0014369224663823843\n",
      "Epoch number 181 and Loss 0.0013748003402724862\n",
      "Epoch number 196 and Loss 0.0013185462448745966\n",
      "Epoch number 211 and Loss 0.0012630097335204482\n",
      "Epoch number 226 and Loss 0.0012118505546823144\n",
      "Epoch number 241 and Loss 0.0011648914078250527\n",
      "Epoch number 256 and Loss 0.0011194102698937058\n",
      "Epoch number 271 and Loss 0.001076364889740944\n",
      "Epoch number 286 and Loss 0.001036355970427394\n",
      "Epoch number 301 and Loss 0.0009964632336050272\n",
      "Epoch number 316 and Loss 0.0009586108499206603\n",
      "Epoch number 331 and Loss 0.0009241009829565883\n",
      "Epoch number 346 and Loss 0.0008901456603780389\n",
      "Epoch number 361 and Loss 0.0008570352802053094\n",
      "Epoch number 376 and Loss 0.0008268611272796988\n",
      "Epoch number 391 and Loss 0.000797101529315114\n",
      "Epoch number 406 and Loss 0.0007681744755245745\n",
      "Epoch number 421 and Loss 0.0007411917904391885\n",
      "Epoch number 436 and Loss 0.0007160523673519492\n",
      "Epoch number 451 and Loss 0.0006912401295267045\n",
      "Epoch number 466 and Loss 0.0006679038633592427\n",
      "Epoch number 481 and Loss 0.0006452853558585048\n",
      "Epoch number 496 and Loss 0.0006235372275114059\n",
      "Precision Score 0.6 for <class 'torch.optim.adam.Adam'>\n",
      "Recall Score 0.57 for <class 'torch.optim.adam.Adam'>\n",
      "Epoch number 1 and Loss 0.0006175043527036905\n",
      "Epoch number 16 and Loss 0.0006170406704768538\n",
      "Epoch number 31 and Loss 0.0006167487590573728\n",
      "Epoch number 46 and Loss 0.0006165715167298913\n",
      "Epoch number 61 and Loss 0.0006164255901239812\n",
      "Epoch number 76 and Loss 0.0006163054495118558\n",
      "Epoch number 91 and Loss 0.0006161651108413935\n",
      "Epoch number 106 and Loss 0.0006160570774227381\n",
      "Epoch number 121 and Loss 0.0006159371114335954\n",
      "Epoch number 136 and Loss 0.0006158336764201522\n",
      "Epoch number 151 and Loss 0.0006157163297757506\n",
      "Epoch number 166 and Loss 0.0006156107410788536\n",
      "Epoch number 181 and Loss 0.0006154985167086124\n",
      "Epoch number 196 and Loss 0.0006153956637717783\n",
      "Epoch number 211 and Loss 0.000615287572145462\n",
      "Epoch number 226 and Loss 0.0006151968846097589\n",
      "Epoch number 241 and Loss 0.0006150826229713857\n",
      "Epoch number 256 and Loss 0.0006149833207018673\n",
      "Epoch number 271 and Loss 0.0006148872198536992\n",
      "Epoch number 286 and Loss 0.0006147893727757037\n",
      "Epoch number 301 and Loss 0.0006146991509012878\n",
      "Epoch number 316 and Loss 0.0006145881488919258\n",
      "Epoch number 331 and Loss 0.000614501943346113\n",
      "Epoch number 346 and Loss 0.0006144049111753702\n",
      "Epoch number 361 and Loss 0.0006143093924038112\n",
      "Epoch number 376 and Loss 0.0006142100901342928\n",
      "Epoch number 391 and Loss 0.0006141241174191236\n",
      "Epoch number 406 and Loss 0.0006140207406133413\n",
      "Epoch number 421 and Loss 0.0006139277247712016\n",
      "Epoch number 436 and Loss 0.0006138450116850436\n",
      "Epoch number 451 and Loss 0.0006137405871413648\n",
      "Epoch number 466 and Loss 0.0006136468728072941\n",
      "Epoch number 481 and Loss 0.0006135576986707747\n",
      "Epoch number 496 and Loss 0.0006134683499112725\n",
      "Precision Score 0.6 for <class 'torch.optim.sgd.SGD'>\n",
      "Recall Score 0.57 for <class 'torch.optim.sgd.SGD'>\n"
     ]
    }
   ],
   "source": [
    "optimizer_list = [torch.optim.Adagrad, torch.optim.Adam,torch.optim.SGD]\n",
    "\n",
    "for x in optimizer_list:\n",
    "    optimizer = x(model.parameters(), lr=0.02) \n",
    "    loss_list = []\n",
    "    n_epochs = 500\n",
    "    for i in range(n_epochs):\n",
    "        y_pred = model.forward(X_train_tensor) \n",
    "        loss = cross_loss(y_pred,y_train_tensor) \n",
    "        loss_list.append(loss) \n",
    "        if i % 15 == 1:\n",
    "            print('Epoch number {} and Loss {}' .format(i,loss))\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step()  \n",
    "        prediction = []\n",
    "    with torch.no_grad(): # decreases memory consumption \n",
    "        for i, data in enumerate(X_test_tensor):\n",
    "            pred = model(data)\n",
    "            prediction.append(pred.argmax()) # returns index with max element in each prediction set\n",
    "        print('Precision Score {} for {}'.format(precision_score(y_test_tensor,prediction).round(2),x))\n",
    "        print('Recall Score {} for {}'.format(recall_score(y_test_tensor,prediction).round(2),x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8904e006",
   "metadata": {},
   "source": [
    "#### Comparing performance\n",
    "\n",
    "\n",
    "|    Optimizer             |    precision score       |     Recall score     |\n",
    "|:------------------------:|:------------------------:|:--------------------:|\n",
    "|       Adam               |           0.58           |       0.57           | \n",
    "|       SGD                |           0.6            |       0.57           |  \n",
    "|       Adagrad            |           0.61           |       0.59           |   \n",
    "\n",
    "\n",
    "\n",
    "* I have used SGD and Adagrad optimizers to check the performance of our neural network. I got an improved precision and recall for **Adagrad optimizer**. Adagrad is an algorithm for gradient descent optimization where each parameter has its own learning rate. So that might be the reason why it gave improved performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfee14",
   "metadata": {},
   "source": [
    "## 2. Write a function that lists and counts the number of divisors for an input value.\n",
    "Example 1:\n",
    "Input: 5\n",
    "Output: “There are 2 divisors: 1 and 5”\n",
    "\n",
    "Example 2:\n",
    "Input: 40\n",
    "Output: “There are 8 divisors: 1, 2, 4, 5, 8, 10, 20, and 40\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d7c4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divisor():\n",
    "    try:\n",
    "        n = int(input(\"Input: \"))\n",
    "        divisors =\"\"\n",
    "        i=1\n",
    "        count = 0\n",
    "        while i <=n:\n",
    "            if n%i == 0:\n",
    "                count +=1\n",
    "                if divisors==\"\":\n",
    "                    divisors=str(i)\n",
    "                else:\n",
    "                    divisors=divisors +\",\"+ str(i)\n",
    "            i+=1 # I calculated all divisors here. I extended my code to print output in a desired way\n",
    "            \n",
    "        last_index=divisors.rfind(\",\") # rfind will give the index of last occurence\n",
    "        New_string=divisors[:last_index]+\" and \"+divisors[last_index+1:] # slicling the last index to add \"and\"\n",
    "        print(\"Output: There are\",count,\"divisors:\",New_string)\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b3de206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 5\n",
      "Output: There are 2 divisors: 1 and 5\n"
     ]
    }
   ],
   "source": [
    "divisor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e51db1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 40\n",
      "Output: There are 8 divisors: 1,2,4,5,8,10,20 and 40\n"
     ]
    }
   ],
   "source": [
    "divisor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "349e9d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 989\n",
      "Output: There are 4 divisors: 1,23,43 and 989\n"
     ]
    }
   ],
   "source": [
    "divisor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
